{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "* [**Preparation**](#Preparation)\n",
    "* [**Introduction**](#Introduction)\n",
    "* [**Data Collection**](#Data-Collection)\n",
    " * [**Data Preprocessing**](#Data-Preprocessing)\n",
    "* [**Building and Training the Model**](#Building-and-Training-the-Model)\n",
    "* [**Qualitative Analysis of Player Vectors**](#Qualitative-Analysis-of-Player-Vectors)\n",
    " * [**t-SNE**](#t-SNE)\n",
    " * [**PCA**](#PCA)\n",
    " * [**ScatterPlot3D**](#ScatterPlot3D)\n",
    "* [**Player Algebra**](#Player-Algebra)\n",
    " * [**Nearest Neighbors**](#Nearest-Neighbors)\n",
    " * [**Opposite-handed Doppelgängers**](#Opposite-handed-Doppelgängers)\n",
    "* [**Modeling Previously Unseen At-Bat Matchups**](#Modeling-Previously-Unseen-At-Bat-Matchups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Python 3, but everything should work with Python 2.\n",
    "\n",
    "1. Install [HDF5](https://www.hdfgroup.org/HDF5/release/obtain5.html).\n",
    "2. Install other packages:\n",
    "\n",
    "<code>pip install h5py keras matplotlib numpy pyyaml scipy scikit-learn seaborn tensorflow theano urllib3</code>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project was to learn distributed representations of MLB players. Theoretically, meaningful representations (i.e., representations that capture real baseball qualities of players) could then be used for other types of analyses, such as simulating season outcomes following trades. <code>(batter|pitcher)2vec</code> was inspired by [<code>word2vec</code>](https://en.wikipedia.org/wiki/Word2vec) (hence the name), which is a model that learns distributed representations of words. These learned word vectors often have interesting properties; for example, Paris - France + Italy in the word vector space is very close to the vector for Rome (see [here](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) and [here](http://arxiv.org/pdf/1301.3781.pdf) for more details). In this notebook, I'll show you how I built a model that simultaneously learns distributed representations of pitchers and batters from at-bat data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start things off, let's download and extract some data from [Retrosheet.org](http://retrosheet.org/). We'll use play-by-play data from the 2013, 2014, 2015, and 2016 seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (3776191397.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    project_directory = \"C:\\Users\\nhw85\\OneDrive\\바탕 화면\\[pitcher.batter]2vec\\data2010seve\" # Change this.\u001b[0m\n\u001b[1;37m                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from os import makedirs\n",
    "from os.path import exists\n",
    "\n",
    "project_directory = \"C:\\Users\\nhw85\\OneDrive\\바탕 화면\\[pitcher.batter]2vec\\data2010seve\" # Change this.\n",
    "zip_name = \"2010seve\"\n",
    "data_directory = project_directory + zip_name\n",
    "\n",
    "if not exists(data_directory):\n",
    "    makedirs(project_directory, exist_ok = True)\n",
    "    zip_f = data_directory + \".zip\"\n",
    "    urllib.request.urlretrieve(\"http://www.retrosheet.org/events/{0}.zip\".format(zip_name), zip_f)\n",
    "    zip_ref = zipfile.ZipFile(zip_f, \"r\")\n",
    "    zip_ref.extractall(project_directory + zip_name)\n",
    "    zip_ref.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll prepare some variables for organizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "data_directory = \"C://Users//nhw85//OneDrive//바탕 화면//[pitcher.batter]2vec//data2010seve\"\n",
    "\n",
    "data_files = [f for f in listdir(data_directory) if isfile(join(data_directory, f))]\n",
    "at_bats = {}\n",
    "home_runs = {}\n",
    "singles = {}\n",
    "doubles = {}\n",
    "counts = {\"batter\": {}, \"pitcher\": {}}\n",
    "\n",
    "data = {}\n",
    "train_years = [\"2013\", \"2014\", \"2015\"]\n",
    "test_year = \"2016\"\n",
    "year_match = r\"201(3|4|5|6)\"\n",
    "for year in train_years + [test_year]:\n",
    "    data[year] = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll read in the data. Unfortunately, this is going to be a bunch of spaghetti code. The goal is to collect the batter, pitcher, and outcome (e.g., strike out, home run) for every at-bat. By the end of the following code block, we'll have a Python list of dictionaries where each element has the format <code>{\"batter\": batter, \"pitcher\": pitcher, \"outcome\": outcome}</code>. To best understand what's going on in the code, you'll have to read through Retrosheet's [game file documentation](http://www.retrosheet.org/game.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "for data_file in data_files:\n",
    "    \n",
    "    year_re = re.search(year_match, data_file)\n",
    "    if year_re is None:\n",
    "        continue\n",
    "    \n",
    "    year = year_re.group()\n",
    "    \n",
    "    # Skip non-event files.\n",
    "    if not (\".EVA\" in data_file or \".EVN\" in data_file):\n",
    "        continue\n",
    "    \n",
    "    f = open(join(data_directory, data_file))\n",
    "    home_pitcher = None\n",
    "    away_pitcher = None\n",
    "    line = f.readline().strip()\n",
    "    \n",
    "    while line != \"\":\n",
    "        parts = line.split(\",\")\n",
    "        \n",
    "        # Get starting pitchers.\n",
    "        if parts[0] == \"id\":\n",
    "            while parts[0] != \"play\":\n",
    "                line = f.readline().strip()\n",
    "                parts = line.split(\",\")\n",
    "                # print(parts)\n",
    "                if parts[0] == \"start\" and parts[-1] == \"1\":\n",
    "                    if parts[3] == \"0\":\n",
    "                        away_pitcher = parts[1]\n",
    "                    else:\n",
    "                        home_pitcher = parts[1]\n",
    "        \n",
    "        # Get at-bat data.\n",
    "        if parts[0] == \"play\":\n",
    "            print(parts)\n",
    "            batter = parts[3]\n",
    "            pitcher = home_pitcher\n",
    "            if parts[2] == \"1\":\n",
    "                pitcher = away_pitcher\n",
    "            \n",
    "            outcome = \"\"\n",
    "            \n",
    "            # Handle balks, intentional, walks, hit by a pitch,\n",
    "            # strike outs, and walks..\n",
    "            if parts[-1][:2] in {\"BK\", \"IW\", \"HP\"}:\n",
    "                outcome = \"p_\" + parts[-1][:2]\n",
    "            elif parts[-1][0] in {\"K\", \"I\", \"W\"}:\n",
    "                outcome = \"p_\" + parts[-1][0]\n",
    "            \n",
    "            # If the last pitch resulted in contact, figure out the pitch outcome.\n",
    "            # See \"Events made by the batter at the plate\" here: http://www.retrosheet.org/eventfile.htm#8.\n",
    "            pitches = parts[5]\n",
    "            if len(pitches) > 0 and pitches[-1] == \"X\":\n",
    "                play_parts = parts[6].split(\"/\")\n",
    "                main_play = play_parts[0]\n",
    "                play = main_play.split(\".\")[0]\n",
    "                \n",
    "                if play[0] == \"H\":\n",
    "                    play = \"HR\"\n",
    "                elif play[0] in string.digits:\n",
    "                    play = play[0]\n",
    "                elif play[0] in {\"S\", \"D\", \"T\"}:\n",
    "                    play = play[:2]\n",
    "                    # Try to get first ball handler.\n",
    "                    if len(play) < 2:\n",
    "                        try:\n",
    "                            handlers = play_parts[1]\n",
    "                            if handlers in string.digits:\n",
    "                                play = play[0] + handlers[0]\n",
    "                        except IndexError:\n",
    "                            play = play[0] + \"X\"\n",
    "                elif play[:2] == \"FC\":\n",
    "                    play = play[2]\n",
    "                \n",
    "                outcome = \"h_\" + play\n",
    "                \n",
    "                if play == \"HR\":\n",
    "                    home_runs[batter] = home_runs.get(batter, 0) + 1\n",
    "                elif play[0] == \"S\":\n",
    "                    singles[batter] = singles.get(batter, 0) + 1\n",
    "                elif play[0] == \"D\":\n",
    "                    doubles[batter] = doubles.get(batter, 0) + 1\n",
    "                \n",
    "            # Ignore catcher interference and ambiguous singles.\n",
    "            if outcome not in {\"h_C\", \"h_S\"} and outcome != \"\":\n",
    "                data[year].append({\"batter\": batter, \"pitcher\": pitcher, \"outcome\": outcome})\n",
    "                at_bats[batter] = at_bats.get(batter, 0) + 1\n",
    "                counts[\"batter\"][batter] = counts[\"batter\"].get(batter, 0) + 1\n",
    "                counts[\"pitcher\"][pitcher] = counts[\"pitcher\"].get(pitcher, 0) + 1\n",
    "                print(counts)\n",
    "        \n",
    "        # Handle pitcher changes.\n",
    "        if parts[0] == \"sub\":\n",
    "            if parts[-1] == \"1\":\n",
    "                if parts[3] == \"0\":\n",
    "                    away_pitcher = parts[1]\n",
    "                else:\n",
    "                    home_pitcher = parts[1]\n",
    "        \n",
    "        line = f.readline().strip()\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outcome)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now that we have our raw data, we're going to establish some cutoffs so that we're only analyzing players with a reasonable number of observations. Let's just focus on the most frequent batters and pitchers who were involved in 90% of the at-bats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = {}\n",
    "percentile_cutoff = 0.9\n",
    "for player_type in [\"batter\", \"pitcher\"]:\n",
    "\n",
    "    counts_list = list(counts[player_type].values())\n",
    "    counts_list.sort(reverse = True)\n",
    "    total_at_bats = sum(counts_list)\n",
    "\n",
    "    cumulative_percentage = [sum(counts_list[:i + 1]) / total_at_bats for i in range(len(counts_list))]\n",
    "    cutoff_index = sum([1 for total in cumulative_percentage if total <= percentile_cutoff])\n",
    "\n",
    "    cutoff = counts_list[cutoff_index]\n",
    "    cutoffs[player_type] = cutoff\n",
    "    print(\"Original: {0}\\tNew: {1}\\tProportion: {2:.2f}\".format(\n",
    "            len(counts[player_type]), cutoff_index, cutoff_index / len(counts[player_type])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only 32% of batters and 46% of pitchers were involved in 90% of at-bats. Let's use these new cutoff points to build the final data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "original_data = 0\n",
    "matchups = set()\n",
    "for year in train_years:\n",
    "\n",
    "    original_data += len(data[year])\n",
    "\n",
    "    for sample in data[year]:\n",
    "\n",
    "        batter = sample[\"batter\"]\n",
    "        pitcher = sample[\"pitcher\"]\n",
    "        matchups.add(\"{0}_{1}\".format(batter, pitcher))\n",
    "\n",
    "        if counts[\"batter\"][batter] >= cutoffs[\"batter\"] and counts[\"pitcher\"][pitcher] >= cutoffs[\"pitcher\"]:\n",
    "            final_data.append(sample)\n",
    "\n",
    "print(\"Original: {0}\\tReduced: {1}\".format(original_data, len(final_data)))\n",
    "print(\"{0:.2f}% of original data set.\".format(len(final_data) / original_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we still retain a large amount of data even after removing infrequent batters and pitchers. Next, we're going to associate an integer index with each of our batters, pitchers, and outcomes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "FAV_NUM = 2010\n",
    "random.seed(FAV_NUM)\n",
    "random.shuffle(final_data)\n",
    "\n",
    "categories = {\"batter\": set(), \"pitcher\": set(), \"outcome\": set()}\n",
    "for sample in final_data:\n",
    "    categories[\"batter\"].add(sample[\"batter\"])\n",
    "    categories[\"pitcher\"].add(sample[\"pitcher\"])\n",
    "    categories[\"outcome\"].add(sample[\"outcome\"])\n",
    "\n",
    "for column in categories:\n",
    "    categories[column] = list(categories[column])\n",
    "    categories[column].sort()\n",
    "\n",
    "NUM_OUTCOMES = len(categories[\"outcome\"])\n",
    "print(\"NUM_OUTCOMES: {0}\".format(NUM_OUTCOMES))\n",
    "print(\" \".join(categories[\"outcome\"]))\n",
    "\n",
    "category_to_int = {}\n",
    "for column in categories:\n",
    "    category_to_int[column] = {categories[column][i]: i for i in range(len(categories[column]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "outcome_counts = {}\n",
    "for year in train_years:\n",
    "    for sample in data[year]:\n",
    "        outcome = sample[\"outcome\"]\n",
    "        outcome_counts[outcome] = outcome_counts.get(outcome, 0) + 1\n",
    "\n",
    "outcome_counts = list(outcome_counts.items())\n",
    "outcome_counts.sort(key = lambda x: x[1], reverse = True)\n",
    "val = [x[1] for x in outcome_counts]\n",
    "symbols = [x[0] for x in outcome_counts]\n",
    "pos = range(len(outcome_counts))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(30, 30)\n",
    "ax = sns.barplot(x = val, y = symbols)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll then use these newly defined integer indices to build the appropriate NumPy arrays for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(FAV_NUM)\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "data_sets = {\"batter\": [], \"pitcher\": [], \"outcome\": []}\n",
    "for sample in final_data:\n",
    "    for column in sample:\n",
    "        value = sample[column]\n",
    "        value_index = category_to_int[column][value]\n",
    "        data_sets[column].append([value_index])\n",
    "\n",
    "for column in [\"batter\", \"pitcher\"]:\n",
    "    data_sets[column] = np.array(data_sets[column])\n",
    "\n",
    "data_sets[\"outcome\"] = np_utils.to_categorical(np.array(data_sets[\"outcome\"]), NUM_OUTCOMES)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to build our model with [Keras](http://keras.io/). The model is similar in spirit to the <code>word2vec</code> model in that we're trying to learn the player vectors that best predict the outcome of an at-bat (the \"target word\" in <code>word2vec</code>) given a certain batter and pitcher (the \"context\" in <code>word2vec</code>). We'll learn separate embedding matrices for batters and pitchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import Activation, concatenate, Dense, Dropout, Embedding, Input, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "NUM_BATTERS = len(categories[\"batter\"])\n",
    "NUM_PITCHERS = len(categories[\"pitcher\"])\n",
    "VEC_SIZE = 9\n",
    "ACTIVATION = \"sigmoid\"\n",
    "\n",
    "batter_idx = Input(shape = (1, ), dtype = \"int32\", name = \"batter_idx\")\n",
    "batter_embed = Embedding(NUM_BATTERS, VEC_SIZE, input_length = 1)(batter_idx)\n",
    "batter_embed = Reshape((VEC_SIZE, ), name = \"batter_embed\")(batter_embed)\n",
    "batter_embed = Activation(ACTIVATION)(batter_embed)\n",
    "\n",
    "pitcher_idx = Input(shape = (1, ), dtype = \"int32\", name = \"pitcher_idx\")\n",
    "pitcher_embed = Embedding(NUM_PITCHERS, VEC_SIZE, input_length = 1)(pitcher_idx)\n",
    "pitcher_embed = Reshape((VEC_SIZE, ), name = \"pitcher_embed\")(pitcher_embed)\n",
    "pitcher_embed = Activation(ACTIVATION)(pitcher_embed)\n",
    "\n",
    "batter_pitcher = concatenate([batter_embed, pitcher_embed], name = \"batter_pitcher\")\n",
    "\n",
    "output = Dense(NUM_OUTCOMES, activation = \"softmax\")(batter_pitcher)\n",
    "\n",
    "model = Model(inputs = [batter_idx, pitcher_idx], outputs = [output])\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to train our model. We'll save the weights at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_EPOCHS = 100\n",
    "VALID = False\n",
    "validation_split = 0.0\n",
    "callbacks = None\n",
    "if VALID:\n",
    "    from keras.callbacks import ModelCheckpoint\n",
    "    validation_split = 0.01\n",
    "    callbacks = [ModelCheckpoint(\"weights.h5\", save_best_only = True, save_weights_only = True)]\n",
    "\n",
    "X_list = [data_sets[\"batter\"], data_sets[\"pitcher\"]]\n",
    "y = data_sets[\"outcome\"]\n",
    "history = model.fit(X_list, y, epochs = NUM_EPOCHS, batch_size = BATCH_SIZE,\n",
    "                    verbose = 2, shuffle = True, callbacks = callbacks, validation_split = validation_split)\n",
    "if not VALID:\n",
    "    model.save_weights(\"weights.h5\")\n",
    "\n",
    "model.load_weights(\"weights.h5\")\n",
    "if VALID:\n",
    "    plt.plot(history.history[\"loss\"])\n",
    "    plt.plot(history.history[\"val_loss\"])\n",
    "    plt.title(\"model loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"valid\"], loc = \"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also train a logistic regression model so that we have something to compare to <code>(batter|pitcher)2vec</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ALT = True\n",
    "alt_model = None\n",
    "\n",
    "if TRAIN_ALT:\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    X_batters = csr_matrix(np_utils.to_categorical(np.array(data_sets[\"batter\"]), NUM_BATTERS))\n",
    "    X_pitchers = csr_matrix(np_utils.to_categorical(np.array(data_sets[\"pitcher\"]), NUM_PITCHERS))\n",
    "    X = hstack([X_batters, X_pitchers])\n",
    "    y = np.argmax(data_sets[\"outcome\"], axis = 1)\n",
    "    alt_model = LogisticRegression(n_jobs = -1)\n",
    "    results = alt_model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Analysis of Player Vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the model, let's go ahead and fetch the distributed representations for all players. To do so, we need to define some functions that return a vector when provided with a player's integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend\n",
    "\n",
    "get_batter_vec = backend.function([batter_idx], [batter_embed])\n",
    "get_pitcher_vec = backend.function([pitcher_idx], [pitcher_embed])\n",
    "\n",
    "# Retrieve distributed representation of players.\n",
    "batter_vecs = get_batter_vec([np.array(range(NUM_BATTERS)).reshape((NUM_BATTERS, 1))])[0]\n",
    "pitcher_vecs = get_pitcher_vec([np.array(range(NUM_PITCHERS)).reshape((NUM_PITCHERS, 1))])[0]\n",
    "player_vecs = {\"batter\": batter_vecs, \"pitcher\": pitcher_vecs}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's find out if these representations are revealing anything interesting. First, let's collect some information about the players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve player data.\n",
    "player_data = {}\n",
    "\n",
    "for data_file in data_files:\n",
    "    if \".ROS\" in data_file:\n",
    "        f = open(join(data_directory, data_file))\n",
    "        for line in f:\n",
    "            parts = line.strip().split(\",\")\n",
    "            player_id = parts[0]\n",
    "            last_name = parts[1]\n",
    "            first_name = parts[2]\n",
    "            name = first_name + \" \" + last_name\n",
    "            batting_hand = parts[3]\n",
    "            throwing_hand = parts[4]\n",
    "            position = parts[6]\n",
    "            player_data[player_id] = {\"name\": name, \"batting_hand\": batting_hand,\n",
    "                                      \"throwing_hand\": throwing_hand, \"position\": position}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding) algorithm to visualize the player vectors in two and three dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "NUM_PLAYERS = {\"batter\": NUM_BATTERS, \"pitcher\": NUM_PITCHERS}\n",
    "\n",
    "\n",
    "def run_tsne(player_type):\n",
    "    \"\"\"Run t-SNE on the player vectors.\n",
    "\n",
    "    :param player_type: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    params = {\"batter\": {\"perplexity\": 20, \"learning_rate\": 200, \"init\": \"pca\"},\n",
    "              \"pitcher\": {\"perplexity\": 20, \"learning_rate\": 200, \"init\": \"random\"}}\n",
    "    tsne = TSNE(n_components = 3, **params[player_type])\n",
    "    manifold_3d = tsne.fit_transform(player_vecs[player_type])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection = \"3d\")\n",
    "    ax.scatter(manifold_3d[:, 0], manifold_3d[:, 1], manifold_3d[:, 2], color = \"gray\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    params = {\"batter\": {\"perplexity\": 20, \"learning_rate\": 550, \"init\": \"pca\"},\n",
    "              \"pitcher\": {\"perplexity\": 20, \"learning_rate\": 200, \"init\": \"random\"}}\n",
    "    tsne = TSNE(n_components = 2, **params[player_type])\n",
    "    manifold_2d = tsne.fit_transform(player_vecs[player_type])\n",
    "    (x, y) = (manifold_2d[:, 0], manifold_2d[:, 1])\n",
    "    \n",
    "    plt.scatter(x, y, color = \"gray\")\n",
    "    interesting_batters = {\"Mike Trout\", \"Paul Goldschmidt\", \"Dee Gordon\", \"Ichiro Suzuki\",\n",
    "                           \"Bryce Harper\"}\n",
    "    interesting_pitchers = {\"Clayton Kershaw\", \"Felix Hernandez\", \"Madison Bumgarner\",\n",
    "                            \"Aroldis Chapman\", \"Dellin Betances\"}\n",
    "    interesting_players = {\"batter\": interesting_batters, \"pitcher\": interesting_pitchers}\n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        player_name = player_data[player_id][\"name\"]\n",
    "        if player_name in interesting_players[player_type]:\n",
    "            plt.text(x[i], y[i], player_name, va = \"top\", family = \"monospace\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return manifold_3d\n",
    "\n",
    "\n",
    "tsne_batters = run_tsne(\"batter\")\n",
    "tsne_pitchers = run_tsne(\"pitcher\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize the first few PCs of a [principal component analysis](https://en.wikipedia.org/wiki/Principal_component_analysis) (PCA) of the vectors and color them with various interesting properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "playerID_to_retroID = {}\n",
    "reader = csv.DictReader(open(\"Master.csv\"))\n",
    "for row in reader:\n",
    "    playerID = row[\"playerID\"]\n",
    "    retroID = row[\"retroID\"]\n",
    "    playerID_to_retroID[playerID] = retroID\n",
    "\n",
    "# Get player salaries.\n",
    "reader = csv.DictReader(open(\"Salaries.csv\"))\n",
    "salaries = {}\n",
    "for row in reader:\n",
    "    if row[\"yearID\"] == \"2015\":\n",
    "        playerID = row[\"playerID\"]\n",
    "        retroID = playerID_to_retroID[playerID]\n",
    "        log_salary = np.log2(int(row[\"salary\"]))\n",
    "        salaries[retroID] = log_salary\n",
    "\n",
    "# Set up other inteteresting data for coloring.\n",
    "max_hr_rate = max([home_runs.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_single_rate = max([singles.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_double_rate = max([doubles.get(batter_id, 0) / at_bats[batter_id] for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "max_salary = max([salaries.get(batter_id, 0) for batter_id in at_bats if batter_id in categories[\"batter\"]])\n",
    "\n",
    "batter_colors = {\"player_id\": [], \"hand\": [], \"Home Runs\": [], \"Singles\": [], \"Doubles\": [], \"salary\": []}\n",
    "for i in range(NUM_BATTERS):\n",
    "    batter_id = categories[\"batter\"][i]\n",
    "    batting_hand = player_data[batter_id][\"batting_hand\"]\n",
    "    batter_colors[\"player_id\"].append(batter_id)\n",
    "    batter_colors[\"hand\"].append(batting_hand)\n",
    "    # batter_colors[\"Home Runs\"].append(str((home_runs.get(batter_id, 0) / at_bats[batter_id]) / max_hr_rate))\n",
    "    batter_colors[\"Home Runs\"].append(str(home_runs.get(batter_id, 0) / at_bats[batter_id]))\n",
    "    batter_colors[\"Singles\"].append(str(singles.get(batter_id, 0) / at_bats[batter_id]))\n",
    "    batter_colors[\"Doubles\"].append(str((doubles.get(batter_id, 0) / at_bats[batter_id]) / max_double_rate))\n",
    "    batter_colors[\"salary\"].append(str((salaries.get(batter_id, 0) / max_salary)))\n",
    "\n",
    "df = pd.DataFrame(batter_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "# Run PCA.\n",
    "pca = decomposition.PCA()\n",
    "\n",
    "pca.fit(batter_vecs)\n",
    "print(pca.explained_variance_ratio_)\n",
    "projected_batters = pca.transform(batter_vecs)\n",
    "\n",
    "pca.fit(pitcher_vecs)\n",
    "print(pca.explained_variance_ratio_)\n",
    "projected_pitchers = pca.transform(pitcher_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    df[\"pc{0}\".format(i + 1)] = projected_batters[:, i]\n",
    "\n",
    "cmap = sns.cubehelix_palette(as_cmap = True)\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection = \"3d\")\n",
    "# ax.scatter(projected_batters[:, 0], projected_batters[:, 1], projected_batters[:, 2], color = df[\"Home Runs\"], cmap = cmap)\n",
    "# ax.set_title(\"Batters\")\n",
    "# plt.show()\n",
    "\n",
    "cs = sns.color_palette(\"hls\", 8)\n",
    "batting_hand_color = {\"Left\": cs[0], \"Right\": cs[3], \"Both\": cs[5]}\n",
    "legend_data = []\n",
    "legend_names = []\n",
    "for (hand, color) in batting_hand_color.items():\n",
    "    batter_hands = df[df[\"hand\"] == hand[0]]\n",
    "    legend_data.append(plt.scatter(batter_hands[\"pc1\"], batter_hands[\"pc2\"], s = 50, color = color))\n",
    "    legend_names.append(hand)\n",
    "\n",
    "plt.title(\"Batting Hand\")\n",
    "plt.legend(legend_data, legend_names)\n",
    "plt.show()\n",
    "\n",
    "for batter_color in [\"Singles\", \"Home Runs\", \"Doubles\", \"salary\"]:\n",
    "    (f, ax) = plt.subplots()\n",
    "    points = ax.scatter(df[\"pc1\"], df[\"pc2\"], c = df[batter_color], s = 50, cmap = cmap)\n",
    "    f.colorbar(points)\n",
    "    ax.set_title(batter_color)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are some interesting patterns emerging from the representations. For example, right-handed hitters are clearly separated from left-handed and switch hitters. Similarly, frequent singles hitters are far from infrequent singles hitters. So, the model is clearly learning something, but whether or not what it's learning is non-trivial remains to be seen. Let's go ahead and save the t-SNE map and PC scores to CSV files so that we can play around with them elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "def write_viz_data(player_type, projected, fieldnames, projection):\n",
    "    \"\"\"Write the visualization coordinates of the players to a file.\n",
    "    \n",
    "    :param player_type: \n",
    "    :param projected: \n",
    "    :param fieldnames: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    out = open(\"{0}s_{1}.csv\".format(player_type, projection), \"w\")\n",
    "    output = csv.DictWriter(out, fieldnames = fieldnames)\n",
    "    output.writeheader()\n",
    "    \n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        row = {}\n",
    "        for col in fieldnames:\n",
    "            if col in player_data[player_id]:\n",
    "                row[col] = player_data[player_id][col]\n",
    "        \n",
    "        row[\"2015_salary\"] = 2 ** salaries.get(player_id, 0)\n",
    "        \n",
    "        xyz = [\"x\", \"y\", \"z\"]\n",
    "        for j in range(3):\n",
    "            if projection == \"pca\":\n",
    "                row[\"PC{0}\".format(j + 1)] = projected[i][j]\n",
    "            else:\n",
    "                row[xyz[j]] = projected[i][j]\n",
    "        \n",
    "        row[\"player_id\"] = player_id\n",
    "        if player_type == \"batter\":\n",
    "            row[\"hr_rate\"] = home_runs.get(player_id, 0) / at_bats[player_id]\n",
    "        \n",
    "        nothing = output.writerow(row)\n",
    "    \n",
    "    out.close()\n",
    "\n",
    "\n",
    "fieldnames = [\"player_id\", \"name\", \"2015_salary\", \"position\", \"batting_hand\", \"throwing_hand\", \"hr_rate\", \"PC1\", \"PC2\", \"PC3\"]\n",
    "write_viz_data(\"batter\", projected_batters, fieldnames, \"pca\")\n",
    "write_viz_data(\"batter\", tsne_batters, fieldnames[:-3] + [\"x\", \"y\", \"z\"], \"tsne\")\n",
    "\n",
    "fieldnames = [\"player_id\", \"name\", \"2015_salary\", \"throwing_hand\", \"PC1\", \"PC2\", \"PC3\"]\n",
    "write_viz_data(\"pitcher\", projected_pitchers, fieldnames, \"pca\")\n",
    "write_viz_data(\"pitcher\", tsne_pitchers, fieldnames[:-3] + [\"x\", \"y\", \"z\"], \"tsne\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save the raw player vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_distributed_representations(player_type, player_vecs):\n",
    "    \"\"\"Write the player vectors to a file.\n",
    "    \n",
    "    :param player_type: \n",
    "    :param player_vecs: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    out = open(\"{0}s_latent.csv\".format(player_type), \"w\")\n",
    "    fieldnames = [\"player_id\", \"name\"] + [\"latent_{0}\".format(i + 1) for i in range(VEC_SIZE)]\n",
    "    output = csv.DictWriter(out, fieldnames = fieldnames)\n",
    "    output.writeheader()\n",
    "    \n",
    "    for i in range(NUM_PLAYERS[player_type]):\n",
    "        player_id = categories[player_type][i]\n",
    "        row = {\"player_id\": player_id,\n",
    "               \"name\": player_data[player_id][\"name\"]}\n",
    "        \n",
    "        for j in range(VEC_SIZE):\n",
    "            row[\"latent_{0}\".format(j + 1)] = player_vecs[i][j]\n",
    "        \n",
    "        nothing = output.writerow(row)\n",
    "    \n",
    "    out.close()\n",
    "\n",
    "\n",
    "write_distributed_representations(\"batter\", batter_vecs)\n",
    "write_distributed_representations(\"pitcher\", pitcher_vecs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ScatterPlot3D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To gain some additional intuition with the player representations, I recommend exploring them in my open source scatter plot visualization application, [ScatterPlot3D](https://sites.google.com/view/michaelaalcorn/projects/scatterplot3d). To run it:\n",
    "\n",
    "1. Download the appropriate build.\n",
    "2. Run with <code>java -jar ScatterPlot3D-&lt;version&gt;.jar</code> on Linux systems or by double-clicking the JAR on Windows.\n",
    "3. Load the data.\n",
    "4. Put 5, 6, and 7 for x, y, and z for \"pitchers_tsne.csv\" or 8, 9, and 10 for \"batters_tsne.csv\".\n",
    "5. Click \"Submit\".\n",
    "\n",
    "You can then search, zoom, and rotate the data, and click on individual points for more details. For example:\n",
    "\n",
    "<img src=\"batters_tsne_all.png\" width=\"600\">\n",
    "\n",
    "<img src=\"trout_goldschmidt.png\" width=\"600\">\n",
    "\n",
    "Documentation can be downloaded [here](https://sites.google.com/view/michaelaalcorn/ScatterPlot3D/SupplementaryMaterials.zip?attredirects=0&d=1) and a gallery of application screenshots can be found [here](http://imgur.com/a/U833y)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Player Algebra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, do these vectors contain any non-obvious information? Maybe comparing nearest neighbors will provide some insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_nearest_neighbors(name, data, latent_vecs, player_names, k = 5):\n",
    "    \"\"\"Print the k nearest neighbors (in the latent space) of a given player.\n",
    "    \n",
    "    :param name: \n",
    "    :param data: \n",
    "    :param latent_vecs: \n",
    "    :param player_names: \n",
    "    :param k: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    player_index = np.where(data[\"name\"] == name)[0]\n",
    "    player_latent = latent_vecs[player_index]\n",
    "    print(player_latent[0])\n",
    "    # distances = list(np.linalg.norm(latent_vecs - player_latent, axis = 1))\n",
    "    distances = 1 - np.dot(latent_vecs, player_latent.T).flatten() / (np.linalg.norm(latent_vecs, axis = 1) * np.linalg.norm(player_latent))\n",
    "    distances_and_ids = list(zip(player_names, distances))\n",
    "    distances_and_ids.sort(key = lambda x: x[1])\n",
    "    \n",
    "    return distances_and_ids[1:1 + k]\n",
    "\n",
    "\n",
    "data_files = [\"batters_latent.csv\", \"pitchers_latent.csv\"]\n",
    "player_df = {}\n",
    "player_names = {}\n",
    "player_ids = {}\n",
    "latent_vecs = {}\n",
    "for player_type in [\"batter\", \"pitcher\"]:\n",
    "    data_file = \"{0}s_latent.csv\".format(player_type)\n",
    "    player_df[player_type] = pd.read_csv(data_file)\n",
    "    player_ids[player_type] = list(player_df[player_type][\"player_id\"])\n",
    "    player_names[player_type] = list(player_df[player_type][\"name\"])\n",
    "    latent_vecs[player_type] = np.array(player_df[player_type].iloc[:, 2:])\n",
    "\n",
    "\n",
    "for batter in [\"Mike Trout\", \"Dee Gordon\"]:\n",
    "    print(batter)\n",
    "    print(get_nearest_neighbors(batter, player_df[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "    print()\n",
    "\n",
    "for pitcher in [\"Clayton Kershaw\", \"Aroldis Chapman\", \"Jake Arrieta\", \"Felix Hernandez\"]:\n",
    "    print(pitcher)\n",
    "    print(get_nearest_neighbors(pitcher, player_df[\"pitcher\"], latent_vecs[\"pitcher\"], player_names[\"pitcher\"]))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a first glance, the nearest neighbors produced by the embedding do seem to support baseball intuition. Both Mike Trout and Paul Goldschmidt are known for their [rare blend of speed and power](https://sports.vice.com/en_us/article/paul-goldschmidt-might-really-be-this-good). Like [Dee Gordon](http://ftw.usatoday.com/2015/06/dee-gordon-miami-marlins-inside-park-home-run), Ichiro Suzuki [has a knack for being able to get on base](http://www.fangraphs.com/blogs/dee-gordon-has-been-going-full-ichiro/).\n",
    "\n",
    "Zack Greinke's presence among Clayton Kershaw's nearest neighbors is interesting as they are considered [one of the best pitching duos of all time](https://www.si.com/cauldron/2015/09/17/clayton-kershaw-zack-greinke-cy-young-mlb). The similarities between Craig Stammen and Kershaw are not obvious to my ignorant baseball eye, but we would expect a method like <code>(batter|pitcher)2vec</code> (if effective) to occasionally discover surprising neighbors or else it wouldn't be particularly useful.\n",
    "\n",
    "Aroldis Chapman's nearest neighbors are fairly unsurprising with [Craig Kimbrel](https://www.scientificamerican.com/article/the-documentary-fastball-tosses-some-physics-at-fans/) and [Andrew Miller](http://www.cbssports.com/mlb/news/world-series-from-teammates-to-foes-indians-andrew-miller-cubs-aroldis-chapman-meet-again/) both being elite relief pitchers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When clustering players using common MLB stats (e.g., HRs, RBIs), Mike Trout's ten nearest neighbors for the 2015 season are: Bryce Harper, Julio Daniel Martinez, Andrew McCutchen, Justin Upton, Matt Carpenter, Joey Votto, Curtis Granderson, Kris Bryant, Chris Davis, and Brian Dozier (R code [here](https://github.com/airalcorn2/batter-pitcher-2vec/blob/master/raw_stats_neighbors.R)). So there is some overlap between the two neighborhood methods, but, intriguingly, the nearest neighbor from each method is not found in the neighborhood of the other method. Similarly, Ichiro isn't among Dee Gordon's ten nearest neighbors when clustering on standard MLB stats."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opposite-handed Doppelgängers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another fun thing to try is analogies. As I mentioned at the beginning of this notebook, word embeddings often contain interesting analogy properties. [Erik Erlandson](https://www.linkedin.com/in/erikerlandson), a colleague of mine at Red Hat, suggested I use average vectors for right-handed and left-handed batters to generate opposite-handed doppelgängers for different players. Let's see what that looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_opposite_hand(name, batting_hand, df, latent_vecs, player_names, k = 10):\n",
    "    \"\"\"Find the player's opposite batting hand doppelgänger.\n",
    "    \n",
    "    :param name: \n",
    "    :param batting_hand: \n",
    "    :param df: \n",
    "    :param latent_vecs: \n",
    "    :param player_names: \n",
    "    :param k: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    player_index = np.where(df[\"name\"] == name)[0]\n",
    "    player_latent = latent_vecs[player_index]\n",
    "    player_latent + average_batters[\"R\"]\n",
    "    opposite_hand = None\n",
    "    if batting_hand == \"R\":\n",
    "        opposite_hand = player_latent - average_batters[\"R\"] + average_batters[\"L\"]\n",
    "    else:\n",
    "        opposite_hand = player_latent - average_batters[\"L\"] + average_batters[\"R\"]\n",
    "    \n",
    "    # distances = list(np.linalg.norm(latent_vecs - opposite_hand, axis = 1))\n",
    "    distances = 1 - np.dot(latent_vecs, opposite_hand.T).flatten() / (np.linalg.norm(latent_vecs, axis = 1) * np.linalg.norm(opposite_hand))\n",
    "    distances_and_ids = list(zip(player_names, distances))\n",
    "    distances_and_ids.sort(key = lambda x: x[1])\n",
    "    \n",
    "    return distances_and_ids[:k]\n",
    "\n",
    "\n",
    "# Generate average vectors for each batting hand.\n",
    "average_batters = {\"R\": [], \"L\": [], \"B\": []}\n",
    "\n",
    "for player_id in player_data:\n",
    "    hand = player_data[player_id][\"batting_hand\"]\n",
    "    batter_index = np.where(player_df[\"batter\"][\"player_id\"] == player_id)[0]\n",
    "    batter_latent = latent_vecs[\"batter\"][batter_index]\n",
    "    if len(batter_latent) > 0:\n",
    "        average_batters[hand] += [batter_latent]\n",
    "\n",
    "for batting_hand in average_batters:\n",
    "    average_batters[batting_hand] = np.array(average_batters[batting_hand]).mean(axis = 0)\n",
    "\n",
    "# Get opposite-handed doppelgängers.\n",
    "print(\"Mike Trout\")\n",
    "print(get_opposite_hand(\"Mike Trout\", \"R\", player_df[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()\n",
    "\n",
    "print(\"Dee Gordon\")\n",
    "print(get_opposite_hand(\"Dee Gordon\", \"L\", player_df[\"batter\"], latent_vecs[\"batter\"], player_names[\"batter\"]))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bryce Harper's presence among Mike Trout's left-handed doppelgängers [is particularly satisfying](http://www.sportingnews.com/mlb/news/sn50-2016-best-baseball-players-mike-trout-bryce-harper/mk3kmorbiyhr1f7onb7t5pehq). As for Dee Gordon's right-handed doppelgängers, Tyler Saladino is known for \"[legging 'em out](http://www.fangraphs.com/fantasy/all-aboard-the-tyler-saladino-hype-train/)\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Previously Unseen At-Bat Matchups"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring how well the <code>(batter|pitcher)2vec</code> representations predict outcome distributions for unseen matchups is the ultimate test of whether the representations are capturing anything meaningful about players. To test the model, we'll look at matchups from the 2016 season that were not seen in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_counts = {}\n",
    "outcome_counts = {}\n",
    "\n",
    "for sample in data[test_year]:\n",
    "    batter = sample[\"batter\"]\n",
    "    pitcher = sample[\"pitcher\"]\n",
    "    matchup = \"{0}_{1}\".format(batter, pitcher)\n",
    "    if batter in categories[\"batter\"] and pitcher in categories[\"pitcher\"] and matchup not in matchups:\n",
    "        matchup_counts[matchup] = matchup_counts.get(matchup, 0) + 1\n",
    "        if matchup not in outcome_counts:\n",
    "            outcome_counts[matchup] = {}\n",
    "        \n",
    "        outcome_counts[matchup][outcome] = outcome_counts[matchup].get(outcome, 0) + 1\n",
    "\n",
    "matchup_counts = list(matchup_counts.items())\n",
    "matchup_counts.sort(key = lambda x: -x[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the effectiveness of <code>(batter|pitcher)2vec</code>, we need something to first establish a baseline. We'll use a naïve prediction strategy to fill that role. For any given batter, we'll define their expected outcome distribution as:\n",
    "\n",
    "$$p(o_i|b_j)=\\frac{c_{i,j} + r_i}{\\sum_{k=1}^{K} c_{j,k} + 1}$$\n",
    "\n",
    "where $o_i$ denotes the outcome indexed by $i$, $c_{i,j}$ is the number of times the player indexed by $j$ had an at-bat resulting in the outcome indexed by $i$ in the training data, $r_i$ is the proportion of all at-bats that resulted in the outcome indexed by $i$ in the training data, and $K$ is the number of possible outcomes. Essentialy, the procedure adds one at-bat to each batter, but distributes the mass of that single bat across all outcomes based on data from all batters. You can think of $r_i$ as a type of \"prior\" or smoothing factor. $p(o_i|p_j)$ will be similarly defined. Finally, we'll define the expected outcome distribution for a given batter/pitcher matchup as:\n",
    "\n",
    "$$p(o_i|b_j,p_k) = \\frac{p(o_i|b_j) + p(o_i|p_k)}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_outcome_counts(train_years, data, test_players, player_type):\n",
    "    \"\"\"Retrieve past outcome counts for a given player in the training set.\n",
    "    \n",
    "    :param train_years: \n",
    "    :param data: \n",
    "    :param test_players: \n",
    "    :param player_type: \n",
    "    \"\"\"\n",
    "    past_outcome_counts = {}\n",
    "    for year in train_years:\n",
    "        for sample in data[year]:\n",
    "            player = sample[player_type]\n",
    "            if player in test_players:\n",
    "                outcome = sample[\"outcome\"]\n",
    "                if player not in past_outcome_counts:\n",
    "                    past_outcome_counts[player] = {}\n",
    "\n",
    "                past_outcome_counts[player][outcome] = past_outcome_counts[player].get(outcome, 0) + 1\n",
    "    \n",
    "    return past_outcome_counts\n",
    "\n",
    "\n",
    "cutoff = 0\n",
    "total_above = sum(1 for matchup_count in matchup_counts if matchup_count[1] >= cutoff)\n",
    "TOP_MATCHUPS = total_above\n",
    "print(\"Total Matchups: {0}\".format(TOP_MATCHUPS))\n",
    "\n",
    "test_batters = {matchup[0].split(\"_\")[0] for matchup in matchup_counts[:TOP_MATCHUPS]}\n",
    "test_pitchers = {matchup[0].split(\"_\")[1] for matchup in matchup_counts[:TOP_MATCHUPS]}\n",
    "test_matchups = {matchup[0] for matchup in matchup_counts[:TOP_MATCHUPS]}\n",
    "\n",
    "past_batter_outcome_counts = get_past_outcome_counts(train_years, data, test_batters, \"batter\")\n",
    "past_pitcher_outcome_counts = get_past_outcome_counts(train_years, data, test_pitchers, \"pitcher\")\n",
    "\n",
    "# Get total outcome counts from training data.\n",
    "train_outcome_counts = {}\n",
    "for year in train_years:\n",
    "    for sample in data[year]:\n",
    "        outcome = sample[\"outcome\"]\n",
    "        train_outcome_counts[outcome] = train_outcome_counts.get(outcome, 0) + 1\n",
    "\n",
    "# Convert total outcome counts into a probability distribution.\n",
    "total_outcomes = sum(train_outcome_counts.values())\n",
    "for outcome in train_outcome_counts:\n",
    "    train_outcome_counts[outcome] /= total_outcomes\n",
    "\n",
    "past_batter_probs = {}\n",
    "for batter in test_batters:\n",
    "    past_batter_outcome_total = sum(past_batter_outcome_counts[batter].values())\n",
    "    past_batter_probs[batter] = {}\n",
    "    for outcome in train_outcome_counts:\n",
    "        past_batter_probs[batter][outcome] = (past_batter_outcome_counts[batter].get(outcome, 0) + train_outcome_counts[outcome]) / (past_batter_outcome_total + 1)\n",
    "\n",
    "past_pitcher_probs = {}\n",
    "for pitcher in test_pitchers:\n",
    "    past_pitcher_outcome_total = sum(past_pitcher_outcome_counts[pitcher].values())\n",
    "    past_pitcher_probs[pitcher] = {}\n",
    "    for outcome in train_outcome_counts:\n",
    "        past_pitcher_probs[pitcher][outcome] = (past_pitcher_outcome_counts[pitcher].get(outcome, 0) + train_outcome_counts[outcome]) / (past_pitcher_outcome_total + 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then calculate the log loss of this naïve approach on unseen matchups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "\n",
    "test_data_sets = {\"batter\": [], \"pitcher\": [], \"outcome\": []}\n",
    "naive_losses = []\n",
    "\n",
    "for sample in data[test_year]:\n",
    "    \n",
    "    batter = sample[\"batter\"]\n",
    "    pitcher = sample[\"pitcher\"]\n",
    "    matchup = \"{0}_{1}\".format(batter, pitcher)\n",
    "    if matchup not in test_matchups:\n",
    "        continue\n",
    "        \n",
    "    outcome = sample[\"outcome\"]\n",
    "    \n",
    "    past_batter_prob = past_batter_probs[batter][outcome]\n",
    "    past_pitcher_prob = past_pitcher_probs[pitcher][outcome]\n",
    "    \n",
    "    naive_prob = (past_batter_prob + past_pitcher_prob) / 2\n",
    "    naive_loss = -np.log(naive_prob)\n",
    "    naive_losses.append(naive_loss)\n",
    "    \n",
    "    for column in sample:\n",
    "        value = sample[column]\n",
    "        value_index = category_to_int[column][value]\n",
    "        test_data_sets[column].append([value_index])\n",
    "\n",
    "avg_naive_loss = sum(naive_losses) / len(naive_losses)\n",
    "print(\"Naïve Loss: {0:.4f}\".format(avg_naive_loss))\n",
    "print(len(naive_losses))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now see how <code>(batter|pitcher)2vec</code> compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in [\"batter\", \"pitcher\"]:\n",
    "    test_data_sets[column] = np.array(test_data_sets[column])\n",
    "\n",
    "X_list = [test_data_sets[\"batter\"], test_data_sets[\"pitcher\"]]\n",
    "y = test_data_sets[\"outcome\"]\n",
    "\n",
    "preds = model.predict(X_list)\n",
    "# result = model.evaluate(X_list, np_utils.to_categorical(np.array(test_data_sets[\"outcome\"]), NUM_OUTCOMES), verbose = 0)\n",
    "# print(result)\n",
    "net_losses = []\n",
    "for i in range(preds.shape[0]):\n",
    "    net_loss = -np.log(preds[i][y[i]][0])\n",
    "    net_losses.append(net_loss)\n",
    "\n",
    "avg_net_loss = sum(net_losses) / len(net_losses)\n",
    "print(\"(batter|pitcher)2vec: {0:.4f}\".format(avg_net_loss))\n",
    "print(len(net_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:.2f}% fewer bits on average.\".format(100 * (1 - avg_net_loss / avg_naive_loss)))\n",
    "print(ttest_ind(net_losses, naive_losses, alternative = \"smaller\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, <code>(batter|pitcher)2vec</code> is a significantly better at modeling outcome distributions for unseen batter/pitcher matchups than the naïve baseline. But is an improvement of only 0.94% over the baseline particularly impressive? Let's see how our logistic regression model fairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_ALT:\n",
    "    X_batters = csr_matrix(np_utils.to_categorical(np.array(test_data_sets[\"batter\"]), NUM_BATTERS))\n",
    "    X_pitchers = csr_matrix(np_utils.to_categorical(np.array(test_data_sets[\"pitcher\"]), NUM_PITCHERS))\n",
    "    X = hstack([X_batters, X_pitchers])\n",
    "\n",
    "    preds = alt_model.predict_proba(X)\n",
    "    lr_losses = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        lr_loss = -np.log(preds[i][y[i]][0])\n",
    "        lr_losses.append(lr_loss)\n",
    "\n",
    "    avg_lr_loss = sum(lr_losses) / len(lr_losses)\n",
    "    print(\"Logistic Regression: {0:.4f}\".format(avg_lr_loss))\n",
    "    print(len(lr_losses))\n",
    "\n",
    "    print(\"{0:.2f}% fewer bits on average.\".format(100 * (1 - avg_lr_loss / avg_naive_loss)))\n",
    "    print(ttest_ind(lr_losses, naive_losses, alternative = \"smaller\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model actually performs slightly worse than our naïve approach! The neural net strategy seems to be a promising one."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
